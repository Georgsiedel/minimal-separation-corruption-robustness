{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom joblib import Parallel, delayed\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import resample\nfrom scipy.stats import norm\nfrom sklearn.model_selection import train_test_split\nimport multiprocessing\nimport matplotlib.pyplot as plt\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:02.31417Z","iopub.execute_input":"2022-05-16T14:59:02.314736Z","iopub.status.idle":"2022-05-16T14:59:03.477372Z","shell.execute_reply.started":"2022-05-16T14:59:02.31462Z","shell.execute_reply":"2022-05-16T14:59:03.476645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate r-separation distance of dataset\ndef get_nearest_oppo_dist(X, y, norm, n_jobs):\n    if len(X.shape) > 2:\n        X = X.reshape(len(X), -1)\n    p = norm\n\n    def helper(yi):\n        return NearestNeighbors(n_neighbors=1, \n                                metric='minkowski', p=p, n_jobs=-1).fit(X[y != yi])\n\n    nns = Parallel(n_jobs=n_jobs)(delayed(helper)(yi) for yi in np.unique(y))\n    ret = np.zeros(len(X))\n    for yi in np.unique(y):\n        dist, _ = nns[yi].kneighbors(X[y == yi], n_neighbors=1)\n        ret[np.where(y == yi)[0]] = dist[:, 0]\n\n    return nns, ret","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:03.478753Z","iopub.execute_input":"2022-05-16T14:59:03.478955Z","iopub.status.idle":"2022-05-16T14:59:03.486499Z","shell.execute_reply.started":"2022-05-16T14:59:03.47893Z","shell.execute_reply":"2022-05-16T14:59:03.485646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sampling function for corruptions within a L_inf distance around every datapoint\ndef sampling(position, label, distance, k_samples, seed):\n    np.random.seed(seed)\n    x_low = position - distance\n    x_high = position + distance\n    x_samples = np.random.uniform(x_low, x_high, (k_samples,2))\n    sample_list = []\n    \n    for x_sample in x_samples:\n        sample_list.append([x_sample[0], x_sample[1], label])\n\n    return sample_list","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:03.487626Z","iopub.execute_input":"2022-05-16T14:59:03.488058Z","iopub.status.idle":"2022-05-16T14:59:03.497784Z","shell.execute_reply.started":"2022-05-16T14:59:03.488017Z","shell.execute_reply":"2022-05-16T14:59:03.496985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sampling function for corruptions within a L_2 distance around every datapoint\n# small k sampling can go wrong when in some seed all samples are excluded. e.g. k=1 will go wrong\ndef sampling_round(position, label, distance, k_samples, seed):\n    #position = np.array([1, 2])\n    #distance = 0.1\n    np.random.seed(seed)\n    x_low = position - distance\n    x_high = position + distance\n    x_samples = np.random.uniform(x_low, x_high, [k_samples,2])\n    df_samples = pd.DataFrame(x_samples) \n    round_samples = []\n    for x1,x2 in zip(df_samples[0],df_samples[1]):\n        d = math.sqrt((x1-position[0])*(x1-position[0])+(x2-position[1])*(x2-position[1]))\n        if d < distance:\n            round_samples.append([x1,x2,label])\n        \n    return round_samples\n    \n#s = sampling_round(np.array([1, 1]), 0, 0.1, 1000)\n#sdf = pd.DataFrame(s)\n#print(sdf)\n#plt.scatter(sdf.iloc[:,0], sdf.iloc[:,1], color='black')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:03.499821Z","iopub.execute_input":"2022-05-16T14:59:03.500684Z","iopub.status.idle":"2022-05-16T14:59:03.508546Z","shell.execute_reply.started":"2022-05-16T14:59:03.500643Z","shell.execute_reply":"2022-05-16T14:59:03.507731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with np.load('./data_2D/B_sep.npz') as dataset:\n    x = dataset['x']\n    y = dataset['y']\nprint(\"Number of Datapoints in the set:%f\" % len(x))\ntime0 = time.perf_counter()\ndist = np.inf #1, 2, np.inf\n\n#calculate the minimum distance of any points from different classes\nnns, ret = get_nearest_oppo_dist(x, y, dist, -1)\n#return minimum and mean value\nprint(\"2R-Separation Minimal: %f\" % ret.min())\nprint(\"2R-Separation Mean: %f\" % ret.mean())\n#setting corner case corruption distance to half the separation distance\nepsilon = ret.min()/2\nprint(\"Epsilon: %f\" % epsilon)\ntime1 = time.perf_counter()\nprint(f\"Separation Calculation took {time1 - time0:0.3f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:03.509625Z","iopub.execute_input":"2022-05-16T14:59:03.510099Z","iopub.status.idle":"2022-05-16T14:59:05.018031Z","shell.execute_reply.started":"2022-05-16T14:59:03.51006Z","shell.execute_reply":"2022-05-16T14:59:05.017062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the 2D dataset\ndef plot_label_clusters(latent_data, labels):\n    plt.figure(figsize=(12, 10))\n    labels = pd.DataFrame(labels)\n    colors = {0:'red', 1:'green'}\n    plt.scatter(latent_data[:, 0], latent_data[:, 1], c=labels[0].map(colors))\n    #cbar = plt.colorbar()\n    #cbar.ax.tick_params(labelsize=15)\n    plt.xlabel(\"x[0]\",fontsize=20)\n    plt.ylabel(\"x[1]\",fontsize=20)\n    plt.title('2D Dataset B',fontsize=25)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)\n    plt.savefig(\"B_sep_data_scatter.svg\",bbox_inches='tight')\n    plt.show()\n\n\nplot_label_clusters(x, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timestart = time.perf_counter()\n#training corruptions\nmodel_epsilons = [0, 0.001, 0.002, epsilon, 0.007, 0.01, 0.015, 0.02, 0.03\n                 ]\n#test corruptions. for MSCR calculation, 0 and epsilon are always needed!\neval_epsilons = [0, 0.001, 0.002, epsilon, 0.007, 0.01, 0.015, 0.02, 0.03\n                ]\nmodel_epsilons_str = ', '.join(map(str, model_epsilons))\neval_epsilons_str = ', '.join(map(str, eval_epsilons))\navg_test_acc = np.empty([len(eval_epsilons), len(model_epsilons)])\nstd_test_acc = np.empty([len(eval_epsilons), len(model_epsilons)])\n\n#mscr = \"minimal separation corruption robustness\" = relative change in accuracy when adding random uniform noise\n#of max distance epsilon to the test data in a way that classes stay separated --> avoidable loss\navg_mscr = np.empty([len(model_epsilons)])\nstd_mscr = np.empty([len(model_epsilons)])\n\nfor idm, model_epsilon in enumerate(model_epsilons):\n    print(\"Model Epsilon =\", model_epsilon)\n    \n    runs = 1200\n    clearresult = np.empty([runs])\n    epsilonresult = np.empty([runs])\n    results_acc = np.empty([len(eval_epsilons),runs])\n\n    for seed in range(runs):\n        onerun2 = time.perf_counter()\n        if idm == 0 and seed == 1:\n                print(f\"One run on the first model_epsilon took {(onerun2 - onerun):.2f} seconds, all runs on all model_epsilons take about {(onerun2-onerun)*runs*len(model_epsilons):.0f} seconds plus some sampling time in case first model has model_epsilon=0.\")\n        onerun = time.perf_counter()\n        \n        with np.load('./data_2D/B_sep.npz') as dataset:\n            x = dataset['x']\n            y = dataset['y']\n        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n\n        #different models available\n        clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=seed) \n        #clf = KNeighborsClassifier(n_neighbors = 1)\n        #clf = SVC(gamma='auto')\n\n        #time2 = time.perf_counter()\n        if model_epsilon == 0:\n            clf.fit(x_train, y_train)  \n        else:\n            k_samples_train = 10\n            aug_list_train = []\n            for p,y in zip(x_train,y_train):   \n                aug_list_train.extend(sampling(p, y, model_epsilon, k_samples_train, seed))    \n            df_aug_train = pd.DataFrame(aug_list_train)\n            x_aug_train = df_aug_train.iloc[:,0:2]\n            y_aug_train = df_aug_train.iloc[:,2]\n            clf.fit(x_aug_train, y_aug_train)\n\n        for ide, eval_epsilon in enumerate(eval_epsilons):\n\n            if eval_epsilon == 0:\n                acc = clf.score(x_test, y_test)\n                results_acc[ide, seed] = acc\n            else:\n                aug_list_test = []\n                k_samples_test = 10\n                for p,y in zip(x_test,y_test):   \n                    aug_list_test.extend(sampling(p, y, eval_epsilon, k_samples_test, seed))    \n                df_aug_test = pd.DataFrame(aug_list_test)\n                x_aug_test = df_aug_test.iloc[:,0:2]\n                y_aug_test = df_aug_test.iloc[:,2]\n                acc = clf.score(x_aug_test, y_aug_test)\n                results_acc[ide, seed] = acc\n                \n    #extra for-loop to get and write down the mean over all runs for every evaluation epsilon of one model_epsilon before training the next model_epsilon:\n    for ide2, eval_epsilon2 in enumerate(eval_epsilons):\n        avg_test_acc[ide2, idm] = results_acc[ide2,:].mean()*100    \n        std_test_acc[ide2, idm] = results_acc[ide2,:].std()*100 \n        if eval_epsilon2 == 0:\n            clearresult = results_acc[ide2,:]\n        if eval_epsilon2 == epsilon:\n            epsilonresult = results_acc[ide2,:]\n            \n    #mscr = \"minimal separation unrobustness\" = increase in error rate when adding random noise to the test data \n    # in a way that classes stay separated\n    avg_mscr[idm] = (clearresult.mean() - epsilonresult.mean())*100\n    std_mscr[idm] = np.subtract(clearresult, epsilonresult).std()*100\n    \n    timeend = time.perf_counter()\n    print(f\"Training round {idm+1} of {len(model_epsilons)} done after {timeend - timestart:0.2f} seconds\")\n          \nprint(avg_test_acc)\nprint(std_test_acc)\nprint(avg_mscr)\nprint(std_mscr)\nnp.savetxt(\n    './results/avg_testacc_augmented.csv',\n    avg_test_acc, fmt='%1.4f', delimiter=';', header='Networks trained with'\n    ' corruptions (epsilon = {}) along columns THEN evaluated on training set using A-TRSM (epsilon = {}) '\n    ' along rows'.format(model_epsilons_str, eval_epsilons_str))\n\nnp.savetxt(\n    './results/avg_mscr.csv',\n    avg_mscr, fmt='%1.4f', delimiter=';', header='Networks trained with'\n    ' corruptions (epsilon = {}) along columns. mscr is the difference in test accuracy in percentage points between' \n    'the model evaluated on the normal test dataset and the model evaluated on an augmented testdataset' \n    'where augmentation distance equaling half the minimal class separation distance'.format(model_epsilons_str))\n\nnp.savetxt(\n    './results/std_testacc_augmented.csv',\n    std_test_acc, fmt='%1.4f', delimiter=';', header='Networks trained with'\n    ' corruptions (epsilon = {}) along columns THEN evaluated on training set using A-TRSM (epsilon = {}) '\n    ' along rows'.format(model_epsilons_str, eval_epsilons_str))\n\nnp.savetxt(\n    './results/std_mscr.csv',\n    std_mscr, fmt='%1.4f', delimiter=';', header='Networks trained with'\n    ' corruptions (epsilon = {}) along columns. mscr is the difference in test accuracy in percentage points between' \n    'the model evaluated on the normal test dataset and the model evaluated on an augmented testdataset' \n    'where augmentation distance equaling half the minimal class separation distance'.format(model_epsilons_str))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:05.019531Z","iopub.execute_input":"2022-05-16T14:59:05.019743Z","iopub.status.idle":"2022-05-16T14:59:10.891184Z","shell.execute_reply.started":"2022-05-16T14:59:05.019718Z","shell.execute_reply":"2022-05-16T14:59:10.88995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this calculates the convergence of average mscr over runs to illustrate the runs needed to equal out randomization\nmscr = np.zeros(runs)\nmscr_series = np.zeros(runs)\n\nfor i in range(runs):\n    mscr[i] = clearresult[i]*100 - epsilonresult[i]*100\n    mscr_series[i] = mscr[:i].mean()\n    \nimport matplotlib.pyplot as plt \n\nx1 = list(range(1,runs+1))\ny1 = mscr_series\n\n\nplt.scatter(x1, y1)\nplt.xlabel(\"Runs\")\nplt.ylabel(\"Average mscr\")\nplt.title(\"Convergence of average mscr (Model trained on last model_epsilon)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:59:10.892169Z","iopub.status.idle":"2022-05-16T14:59:10.892455Z","shell.execute_reply.started":"2022-05-16T14:59:10.89231Z","shell.execute_reply":"2022-05-16T14:59:10.892326Z"},"trusted":true},"execution_count":null,"outputs":[]}]}